{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task dataset generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-RAVEN Originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "\n",
    "utils.view_matrices(source_dir='datasets/originals/',n_view=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir=\"datasets/project_demo_hexagons\"\n",
    "utils.view_matrices(source_dir=source_dir,n_view=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary weight masking demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import masking, data, utils\n",
    "from data import IRAVENDataModule\n",
    "from models.SCL_model import SCL,SCLTrainingWrapper\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "task_dataset_name='squares'\n",
    "SCL_version_accuracy=80\n",
    "\n",
    "#get a task dataset\n",
    "dataset_path=f'datasets/{task_dataset_name}'\n",
    "data_module=IRAVENDataModule(batch_size=8,split=(90,10,0))\n",
    "data_module.prepare_data()\n",
    "data_module.setup(root_dir=dataset_path)\n",
    "train_dataloader_task,test_dataloader_task=data_module.train_dataloader(),data_module.test_dataloader()\n",
    "\n",
    "#get IRAVEN originals\n",
    "originals_path='datasets/originals_masking'\n",
    "data_module_originals=IRAVENDataModule(batch_size=8,split=(90,10,0))\n",
    "data_module_originals.prepare_data()\n",
    "data_module_originals.setup(root_dir=originals_path)\n",
    "test_dataloader_originals=data_module_originals.test_dataloader()\n",
    "\n",
    "\n",
    "#get unmasked SCL\n",
    "scl_kwargs={\n",
    "        \"image_size\":160,                            # size of image\n",
    "        \"set_size\": 9,                               # number of questions + 1 answer\n",
    "        \"conv_channels\": [1, 16, 16, 32, 32, 32],    # convolutional channel progression, 1 for greyscale, 3 for rgb\n",
    "        \"conv_output_dim\": 80,                       # model dimension, the output dimension of the vision net\n",
    "        \"attr_heads\": 10,                            # number of attribute heads\n",
    "        \"attr_net_hidden_dims\": [128],               # attribute scatter transform MLP hidden dimension(s)\n",
    "        \"rel_heads\": 80,                             # number of relationship heads\n",
    "        \"rel_net_hidden_dims\": [64, 32, 5] \n",
    "    }\n",
    "model=SCL(**scl_kwargs)\n",
    "\n",
    "#load\n",
    "model_ckpt=f'model_ckpts/pretrain_SCL/SCL_pretrain_{SCL_version_accuracy}.ckpt'\n",
    "state_dict=utils.get_SCL_state_dict(model_ckpt)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval() #for batch norm\n",
    "\n",
    "init_kwargs={\n",
    "    'model':model,\n",
    "    'train_dataloader':train_dataloader_task,\n",
    "    'test_dataloader1':test_dataloader_task,\n",
    "    'test_dataloader2':test_dataloader_originals,\n",
    "    'device':device,\n",
    "    'savedir':None,\n",
    "    'logit_init':2.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we mean by binary weight masking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tens(tens):\n",
    "    tens=tens.detach().numpy()\n",
    "    fig,ax=plt.subplots(figsize=(4,6))\n",
    "\n",
    "    plot_kwargs={\n",
    "        'data':tens,\n",
    "        'xticklabels':False,\n",
    "        'yticklabels':False,\n",
    "        'cmap':'Greys_r',\n",
    "        'annot':True,\n",
    "        'ax':ax,\n",
    "        'annot_kws':{'fontsize':20},\n",
    "        'vmin':0,\n",
    "        'vmax':1,\n",
    "    }\n",
    "\n",
    "\n",
    "    sns.heatmap(**plot_kwargs)   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens=torch.rand(size=(5,1))\n",
    "plot_tens(tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=torch.tensor([0,1,1,0,0]); mask=mask.unsqueeze(1)\n",
    "masked_tens=tens*mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial binaries tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aux functions\n",
    "\n",
    "def plot_binary(binary_tensor,annot=False,title='Title'): \n",
    "\n",
    "    tens=binary_tensor.detach().numpy()\n",
    "    fig,ax=plt.subplots(figsize=(10,6))\n",
    "    fig.suptitle(title,fontsize=20)\n",
    "\n",
    "    plot_kwargs={\n",
    "        'data':tens,\n",
    "        'xticklabels':False,\n",
    "        'yticklabels':False,\n",
    "        'cmap':'Greys_r',\n",
    "        'annot':annot,\n",
    "        'ax':ax,\n",
    "    }\n",
    "\n",
    "\n",
    "    sns.heatmap(**plot_kwargs)\n",
    "\n",
    "    ax.patch.set_edgecolor('red')  \n",
    "\n",
    "    ax.patch.set_linewidth(5) \n",
    "\n",
    "\n",
    "masked_scl=masking.MaskedSCLModel(init_kwargs)\n",
    "\n",
    "layer_name='rel_net.net.2.weight'\n",
    "\n",
    "logit_1=masked_scl.logit_tensors_dict[layer_name]\n",
    "masked_scl.transform_logit_tensors() #map logits to binaries\n",
    "binary_1=masked_scl.binaries[layer_name]\n",
    "\n",
    "plot_binary(binary_1,title='initial binary mask')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train train train\n",
    "\n",
    "train_kwargs={\n",
    "    'alpha':1e-6,\n",
    "    'lr':1e-3,\n",
    "    'n_epochs':1,\n",
    "    'n_batches':10,\n",
    "    'val_every_n_steps':10000,\n",
    "    'eval_every_n_steps':1e10,\n",
    "    'n_val_batches':10,\n",
    "    'n_eval_batches':10,\n",
    "    'save_freq_epoch':100000,\n",
    "    'logging':False,\n",
    "    }\n",
    "\n",
    "masked_scl.train(**train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated binary tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binary_2=masked_scl.binaries[layer_name]\n",
    "plot_binary(binary_2,title='binary mask Epoch 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import CPU_Unpickler\n",
    "\n",
    "ckpt_file='masks/SCL_90/circles/alpha=2.1877616239495517e-06_checkpoint_step=15957_epoch=100'\n",
    "device=torch.device('cpu')\n",
    "with open(ckpt_file,'rb') as f:\n",
    "    data=CPU_Unpickler(f).load()\n",
    "\n",
    "binary_mask=utils.transform_logit_tensors(data['logit_tensors_dict'])\n",
    "binary_tensor_100=binary_mask[layer_name]\n",
    "\n",
    "plot_binary(binary_tensor_100,title='Binary mask epoch 100')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_arr(arr,title):\n",
    "    fig,ax=plt.subplots(figsize=(8,8))\n",
    "\n",
    "    plot_kwargs={\n",
    "        'data':arr,\n",
    "        'xticklabels':False,\n",
    "        'yticklabels':False,\n",
    "        'cmap':'Greys_r',\n",
    "        'annot':True,\n",
    "        'ax':ax,\n",
    "        'annot_kws':{'fontsize':15},\n",
    "        'vmin':0,\n",
    "        'vmax':1,\n",
    "        'cbar':False,\n",
    "        'linewidths':0.5,\n",
    "        'linecolor':'black',\n",
    "    }\n",
    "\n",
    "    sns.heatmap(**plot_kwargs)   \n",
    "    plt.title(title,fontsize=20,pad=20)\n",
    "  \n",
    "\n",
    "\n",
    "arr_0=np.random.random_sample(size=(8,8))\n",
    "plot_arr(arr_0,title=\"Epoch 0\")\n",
    "    \n",
    "bm_10=np.random.randint(0,2,size=(8,8))\n",
    "arr_10 = arr_0*bm_10\n",
    "plot_arr(arr_10,title=\"Epoch 10\")\n",
    "\n",
    "bm_50=(np.random.randint(0,2,size=(8,8)))*(np.random.randint(0,2,size=(8,8)))\n",
    "arr_50=arr_10*bm_50\n",
    "plot_arr(arr_50,title=\"Epoch 50\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('DLEnv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "777c4db5e742970643b3caf0f2444cc887f9a8bc662ed8f696c61dc9ad37cda3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
