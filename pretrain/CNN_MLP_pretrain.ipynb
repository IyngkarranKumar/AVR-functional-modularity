{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.cnn_mlp\n",
    "import data\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data)\n",
    "importlib.reload(models.cnn_mlp)\n",
    "importlib.reload(utils)\n",
    "\n",
    "from data import IRAVENDataModule\n",
    "\n",
    "load=False\n",
    "train=True\n",
    "logging=False\n",
    "debug=True\n",
    "\n",
    "#load,save,log hyperparams\n",
    "load_path=None\n",
    "save_freq=1e10\n",
    "savedir='model_ckpts/pretrain_SCL'\n",
    "logging=False\n",
    "watch_freq=1e10\n",
    "device='cpu'\n",
    "\n",
    "#train hyperparams\n",
    "n_epochs=2 if debug else 10\n",
    "n_batches=10 if debug else 'full'\n",
    "n_val_batches=2 if debug else 'full'\n",
    "grad_clip_value=0.5\n",
    "lr=1e-4\n",
    "\n",
    "#data hyperparams\n",
    "batch_size=16\n",
    "split=(90,10,0)\n",
    "\n",
    "#----------------------------------------\n",
    "\n",
    "\n",
    "device=torch.device(device)\n",
    "print(f'Using device {device}')\n",
    "\n",
    "\n",
    "#data\n",
    "data_module=IRAVENDataModule(batch_size=batch_size,split=split)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "train_dataloader,test_dataloader,val_dataloader=data_module.train_dataloader(),data_module.test_dataloader(),data_module.val_dataloader()\n",
    "x,y,*rest=next(iter(train_dataloader))\n",
    "\n",
    "\n",
    "\n",
    "#setup model\n",
    "if load:\n",
    "    print(f'Loading model from checkpoint {load_path}')\n",
    "    with open (load_path,'rb') as f:\n",
    "        load_dict=pickle.load(f)\n",
    "    kwargs=load_dict['kwargs']\n",
    "\n",
    "    CNN_MLP_model=models.cnn_mlp.CNN_MLP(**kwargs)\n",
    "    optimiser=torch.optim.Adam(CNN_MLP_model.parameters(),lr=lr)\n",
    "\n",
    "    CNN_MLP_model.load_state_dict(load_dict['model state dict'])\n",
    "    optimiser.load_state_dict(load_dict['Optimiser state dict'])\n",
    "\n",
    "    start_epoch=load_dict['Epoch']\n",
    "    run_id=load_dict['Run ID']\n",
    "\n",
    "else:\n",
    "    kwargs={\n",
    "\n",
    "    }\n",
    "\n",
    "    CNN_MLP_model=models.cnn_mlp.CNN_MLP(**kwargs)\n",
    "    optimiser=torch.optim.Adam(CNN_MLP_model.parameters(),lr=lr)\n",
    "\n",
    "    start_epoch=0\n",
    "\n",
    "CNN_MLP_model.to(device)\n",
    "\n",
    "\n",
    "#train loop\n",
    "if train:\n",
    "    if logging:\n",
    "        if load:\n",
    "            run=wandb.init(id=run_id,project='AVR',resume='must')\n",
    "\n",
    "        else:\n",
    "            name=str(input('Log name: '))\n",
    "            run=wandb.init(project='AVR',name=name)\n",
    "        wandb.watch(CNN_MLP_model,log='all',log_freq=watch_freq)\n",
    "    \n",
    "    for epoch in range(start_epoch,n_epochs):\n",
    "        print(f'Starting epoch {epoch}')\n",
    "\n",
    "        #train\n",
    "        CNN_MLP_model.train()\n",
    "        for batch_idx,batch in enumerate(train_dataloader):\n",
    "            #print(f'Train step {batch_idx}')\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "\n",
    "            if batch_idx==n_batches:\n",
    "                break\n",
    "            if n_batches=='full':\n",
    "                pass\n",
    "\n",
    "            x,y,*rest=batch\n",
    "            x,y=x.to(device),y.to(device)\n",
    "            logits=CNN_MLP_model(x)\n",
    "            \n",
    "            train_loss=F.cross_entropy(logits,y)\n",
    "            train_accuracy=utils.calculate_accuracy(logits,y)\n",
    "            train_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(CNN_MLP_model.parameters(),grad_clip_value)\n",
    "            optimiser.step()\n",
    "\n",
    "\n",
    "        #val every epoch\n",
    "        CNN_MLP_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses=[] #accumulate losses over all validation batches\n",
    "            val_accuracies=[] #accumulate accuracies over all validation batches\n",
    "            for batch_idx,batch in enumerate(test_dataloader):\n",
    "                #print(f'Validation step {batch_idx}')\n",
    "\n",
    "                if batch_idx==n_val_batches:\n",
    "                    break\n",
    "                if n_val_batches=='full':\n",
    "                    pass\n",
    "\n",
    "                x,y,*rest=batch\n",
    "                x,y=x.to(device),y.to(device)\n",
    "                logits=CNN_MLP_model(x)\n",
    "                val_loss=F.cross_entropy(logits,y);val_losses.append(val_loss.item())\n",
    "                val_accuracy=utils.calculate_accuracy(logits,y);val_accuracies.append(val_accuracy)\n",
    "\n",
    "            \n",
    "\n",
    "        #logging\n",
    "        if logging:\n",
    "            wandb.log({\n",
    "                'epoch':epoch,\n",
    "                'Loss/train':train_loss,\n",
    "                'Accuracy/train':train_accuracy,\n",
    "                'Loss/val':np.mean(val_losses),\n",
    "                'Accuracy/val':np.mean(val_accuracies)\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "        #save\n",
    "        if (epoch%save_freq==0) and (epoch!=0):\n",
    "            if not os.path.isdir(savedir):\n",
    "                os.mkdir(savedir)\n",
    "\n",
    "            save_dict={}\n",
    "            save_dict['kwargs']=kwargs\n",
    "            save_dict['model state dict']=CNN_MLP_model.state_dict()\n",
    "            save_dict['Optimiser state dict']=optimiser.state_dict()\n",
    "            save_dict['Epoch']=epoch\n",
    "\n",
    "            if logging:\n",
    "                save_dict['Run ID']=run.id\n",
    "            else:\n",
    "                save_dict['Run ID']=None\n",
    "\n",
    "            fname=os.path.join(savedir,f'epoch={epoch}_accuracy={val_accuracy}.ckpt')\n",
    "            with open(fname,'wb') as f:\n",
    "                pickle.dump(save_dict,f)\n",
    "                print('Checkpoint saved')\n",
    "\n",
    "\n",
    "        print(f'Finished epoch {epoch} - validation loss {np.mean(val_losses)}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_MLP_model=models.cnn_mlp.CNN_MLP()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('DLEnv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "777c4db5e742970643b3caf0f2444cc887f9a8bc662ed8f696c61dc9ad37cda3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
