{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import IRAVENDataModule\n",
    "\n",
    "\n",
    "batch_size=16\n",
    "data_module=IRAVENDataModule(batch_size=batch_size)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "train_dataloader,test_dataloader,val_dataloader=data_module.train_dataloader(),data_module.test_dataloader(),data_module.val_dataloader()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scattering_transform\n",
    "from scattering_transform import SCLTrainingWrapper\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#\n",
    "load=False\n",
    "load_path='/Users/iyngkarrankumar/Documents/AI/AVR-functional-modularity/model_ckpts/pretrain_SCL/epoch=5_accuracy=12.5.ckpt'\n",
    "\n",
    "#save \n",
    "save_freq=10000\n",
    "savedir='model_ckpts/pretrain_SCL'\n",
    "\n",
    "#logging\n",
    "logging=False\n",
    "watch_freq=1000\n",
    "\n",
    "#training loop\n",
    "train=True\n",
    "n_epochs=10\n",
    "n_batches=100\n",
    "n_val_batches=100\n",
    "val_every_n_steps=10\n",
    "grad_clip_value=0.5\n",
    "lr=1e-4\n",
    "\n",
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "\n",
    "#setup model\n",
    "if load:\n",
    "    print(f'Loading model from checkpoint {load_path}')\n",
    "\n",
    "\n",
    "    with open (load_path,'rb') as f:\n",
    "        load_dict=pickle.load(f)\n",
    "\n",
    "    kwargs=load_dict['kwargs']\n",
    "    SCL_model=SCLTrainingWrapper(scattering_transform.SCL(**kwargs))\n",
    "    optimiser=torch.optim.Adam(SCL_model.parameters(),lr=lr)\n",
    "    \n",
    "    SCL_model.load_state_dict(load_dict['model state dict'])\n",
    "    optimiser.load_state_dict(load_dict['Optimiser state dict'])\n",
    "\n",
    "    start_epoch=load_dict['Epoch']\n",
    "    run_id=load_dict['Run ID']\n",
    "\n",
    "else:\n",
    "    #setup\n",
    "    kwargs={\n",
    "        \"image_size\":160,                            # size of image\n",
    "        \"set_size\": 9,                               # number of questions + 1 answer\n",
    "        \"conv_channels\": [1, 16, 16, 32, 32, 32],    # convolutional channel progression, 1 for greyscale, 3 for rgb\n",
    "        \"conv_output_dim\": 80,                       # model dimension, the output dimension of the vision net\n",
    "        \"attr_heads\": 10,                            # number of attribute heads\n",
    "        \"attr_net_hidden_dims\": [128],               # attribute scatter transform MLP hidden dimension(s)\n",
    "        \"rel_heads\": 80,                             # number of relationship heads\n",
    "        \"rel_net_hidden_dims\": [64, 23, 5] \n",
    "    }\n",
    "\n",
    "    SCL_model=SCLTrainingWrapper(scattering_transform.SCL(**kwargs))\n",
    "    optimiser=torch.optim.Adam(SCL_model.parameters(),lr=lr)\n",
    "\n",
    "    start_epoch=0\n",
    "\n",
    "SCL_model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if train:\n",
    "    if logging:\n",
    "        if load:\n",
    "            run=wandb.init(id=run_id,project='AVR',resume='must')\n",
    "\n",
    "        else:\n",
    "            name=str(input('Log name: '))\n",
    "            run=wandb.init(project='AVR',name=name)\n",
    "        wandb.watch(SCL_model,log='all',log_freq=watch_freq)\n",
    "    \n",
    "    SCL_model.train()\n",
    "    for epoch in range(start_epoch,n_epochs):\n",
    "        print(f'Starting epoch {epoch}')\n",
    "\n",
    "        #train\n",
    "        for batch_idx,batch in enumerate(train_dataloader):\n",
    "            print(f'Train step {batch_idx}')\n",
    "            if batch_idx==n_batches:\n",
    "                break\n",
    "            if n_batches=='full':\n",
    "                pass\n",
    "\n",
    "            matrix,targets,_,_=batch\n",
    "            matrix,targets=matrix.to(device),targets.to(device)\n",
    "            matrix=matrix.unsqueeze(2)\n",
    "            questions,answers=matrix[:,0:8,:,:,],matrix[:,8:,:,:,]\n",
    "            logits=SCL_model(questions,answers)\n",
    "            train_loss=F.cross_entropy(logits,targets)\n",
    "            train_accuracy=utils.calculate_accuracy(logits,targets)\n",
    "\n",
    "\n",
    "            train_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(SCL_model.parameters(),grad_clip_value)\n",
    "            optimiser.step()\n",
    "\n",
    "\n",
    "        #val\n",
    "        if (batch_idx%val_every_n_steps)==0:\n",
    "            SCL_model.eval()\n",
    "            with torch.no_grad():\n",
    "                losses=[]\n",
    "                accuracies=[]\n",
    "                for batch_idx,batch in enumerate(test_dataloader):\n",
    "                    print(f'Validation step {batch_idx}')\n",
    "\n",
    "                    if batch_idx==n_val_batches:\n",
    "                        break\n",
    "                    if n_val_batches=='full':\n",
    "                        pass\n",
    "\n",
    "                    matrix,targets,_,_=batch\n",
    "                    matrix,targets=matrix.to(device),targets.to(device)\n",
    "                    matrix=matrix.unsqueeze(2)\n",
    "                    questions,answers=matrix[:,0:8,:,:,],matrix[:,8:,:,:,]\n",
    "                    logits=SCL_model(questions,answers)\n",
    "                    val_loss=F.cross_entropy(logits,targets);losses.append(val_loss.item())\n",
    "                    val_accuracy=utils.calculate_accuracy(logits,targets);accuracies.append(val_accuracy)\n",
    "\n",
    "            \n",
    "\n",
    "        if logging:\n",
    "            wandb.log({'epoch':epoch,\n",
    "                        'Loss/train':train_loss,\n",
    "                        'Accuracy/train':train_accuracy,\n",
    "                        'Loss/val':np.mean(losses),\n",
    "                        'Accuracy/val':np.mean(accuracies)})\n",
    "\n",
    "\n",
    "        #save\n",
    "        if (epoch%save_freq==0) and (epoch!=0):\n",
    "            if not os.path.isdir(savedir):\n",
    "                os.mkdir(savedir)\n",
    "\n",
    "            save_dict={}\n",
    "            save_dict['kwargs']=kwargs\n",
    "            save_dict['model state dict']=SCL_model.state_dict()\n",
    "            save_dict['Optimiser state dict']=optimiser.state_dict()\n",
    "            save_dict['Epoch']=epoch\n",
    "\n",
    "            if logging:\n",
    "                save_dict['Run ID']=run.id\n",
    "            else:\n",
    "                save_dict['Run ID']=None\n",
    "\n",
    "            fname=os.path.join(savedir,f'epoch={epoch}_accuracy={val_accuracy}.ckpt')\n",
    "            with open(fname,'wb') as f:\n",
    "                pickle.dump(save_dict,f)\n",
    "                print('Checkpoint saved')\n",
    "\n",
    "\n",
    "        print(f'Finished epoch {epoch}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import IRAVENDataModule\n",
    "\n",
    "\n",
    "batch_size=16\n",
    "data=IRAVENDataModule(batch_size=batch_size)\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "train_dataloader,test_dataloader,val_dataloader=data.train_dataloader(),data.test_dataloader(),data.val_dataloader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import scattering_transform\n",
    "import importlib\n",
    "importlib.reload(scattering_transform)\n",
    "\n",
    "\n",
    "kwargs={\n",
    "        \"image_size\":160,                            # size of image\n",
    "        \"set_size\": 9,                               # number of questions + 1 answer\n",
    "        \"conv_channels\": [1, 16, 16, 32, 32, 32],    # convolutional channel progression, 1 for greyscale, 3 for rgb\n",
    "        \"conv_output_dim\": 80,                       # model dimension, the output dimension of the vision net\n",
    "        \"attr_heads\": 10,                            # number of attribute heads\n",
    "        \"attr_net_hidden_dims\": [128],               # attribute scatter transform MLP hidden dimension(s)\n",
    "        \"rel_heads\": 80,                             # number of relationship heads\n",
    "        \"rel_net_hidden_dims\": [64, 23, 5] \n",
    "    }\n",
    "\n",
    "model=scattering_transform.SCL(**kwargs)\n",
    "X,y,_,_=next(iter(train_dataloader))\n",
    "\n",
    "questions,answers=X[:,0:8:,:,:,].unsqueeze(2),X[:,8:,:,:,].unsqueeze(2)\n",
    "wrapped_model=scattering_transform.SCLTrainingWrapper(model)\n",
    "out=wrapped_model(questions,answers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('DLEnv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "777c4db5e742970643b3caf0f2444cc887f9a8bc662ed8f696c61dc9ad37cda3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
