{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import IRAVENDataModule\n",
    "\n",
    "data=IRAVENDataModule()\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "train_dataloader,test_dataloader,val_dataloader=data.train_dataloader(),data.test_dataloader(),data.val_dataloader()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scattering_transform\n",
    "from scattering_transform import SCLTrainingWrapper\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#\n",
    "load=False\n",
    "load_path='/Users/iyngkarrankumar/Documents/AI/AVR-functional-modularity/model_ckpts/pretrain_SCL/epoch=5_accuracy=12.5.ckpt'\n",
    "\n",
    "#save \n",
    "save_freq=1\n",
    "savedir='model_ckpts/pretrain_SCL'\n",
    "\n",
    "#logging\n",
    "logging=True\n",
    "name=str(input('Log name: '))\n",
    "\n",
    "#training loop\n",
    "train=True\n",
    "n_epochs=10\n",
    "n_batches=5\n",
    "n_val_batches=5\n",
    "\n",
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "\n",
    "#setup model\n",
    "if load:\n",
    "    print(f'Loading model from checkpoint {load_path}')\n",
    "\n",
    "\n",
    "    with open (load_path,'rb') as f:\n",
    "        load_dict=pickle.load(f)\n",
    "\n",
    "    kwargs=load_dict['kwargs']\n",
    "    SCL_model=SCLTrainingWrapper(scattering_transform.SCL(**kwargs))\n",
    "    SCL_model.to(device)\n",
    "    optimiser=torch.optim.Adam(SCL_model.parameters())\n",
    "    \n",
    "    SCL_model.load_state_dict(load_dict['model state dict'])\n",
    "    optimiser.load_state_dict(load_dict['Optimiser state dict'])\n",
    "\n",
    "    start_epoch=load_dict['Epoch']\n",
    "    run_id=load_dict['Run ID']\n",
    "\n",
    "else:\n",
    "    #setup\n",
    "    kwargs={\n",
    "        \"image_size\":160,                            # size of image\n",
    "        \"set_size\": 9,                               # number of questions + 1 answer\n",
    "        \"conv_channels\": [1, 16, 16, 32, 32, 32],    # convolutional channel progression, 1 for greyscale, 3 for rgb\n",
    "        \"conv_output_dim\": 80,                       # model dimension, the output dimension of the vision net\n",
    "        \"attr_heads\": 10,                            # number of attribute heads\n",
    "        \"attr_net_hidden_dims\": [128],               # attribute scatter transform MLP hidden dimension(s)\n",
    "        \"rel_heads\": 80,                             # number of relationship heads\n",
    "        \"rel_net_hidden_dims\": [64, 23, 5] \n",
    "    }\n",
    "\n",
    "    SCL_model=SCLTrainingWrapper(scattering_transform.SCL(**kwargs))\n",
    "    SCL_model.to(device)\n",
    "    optimiser=torch.optim.Adam(SCL_model.parameters())\n",
    "\n",
    "    start_epoch=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if train:\n",
    "    if logging:\n",
    "        if load:\n",
    "            run=wandb.init(id=run_id,project='AVR',resume='must')\n",
    "        else:\n",
    "            print('in')\n",
    "            run=wandb.init(project='AVR',name=name)\n",
    "    \n",
    "    for epoch in range(start_epoch,n_epochs):\n",
    "        print(f'Starting epoch {epoch}')\n",
    "\n",
    "        #train\n",
    "        for batch_idx,batch in enumerate(train_dataloader):\n",
    "            print(f'Train step {batch_idx}')\n",
    "            if batch_idx==n_batches:\n",
    "                break\n",
    "            if n_batches=='full':\n",
    "                pass\n",
    "\n",
    "            matrix,targets,_,_=batch\n",
    "            matrix,targets=matrix.to(device),targets.to(device)\n",
    "            matrix=matrix.unsqueeze(2)\n",
    "            questions,answers=matrix[:,0:8,:,:,],matrix[:,8:,:,:,]\n",
    "            logits=SCL_model(questions,answers)\n",
    "            loss=F.cross_entropy(logits,targets)\n",
    "            train_accuracy=utils.calculate_accuracy(logits,targets)\n",
    "            if logging:\n",
    "                wandb.log({'epoch':epoch,\n",
    "                            'Loss/train':loss,\n",
    "                            'Accuracy/train':train_accuracy})\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "\n",
    "        #val\n",
    "        with torch.no_grad():\n",
    "            losses=[]\n",
    "            accuracies=[]\n",
    "            for batch_idx,batch in enumerate(val_dataloader):\n",
    "                print(f'Validation step {batch_idx}')\n",
    "\n",
    "                if batch_idx==n_val_batches:\n",
    "                    break\n",
    "                if n_val_batches=='full':\n",
    "                    pass\n",
    "\n",
    "                matrix,targets,_,_=batch\n",
    "                matrix,targets=matrix.to(device),targets.to(device)\n",
    "                matrix=matrix.unsqueeze(2)\n",
    "                questions,answers=matrix[:,0:8,:,:,],matrix[:,8:,:,:,]\n",
    "                logits=SCL_model(questions,answers)\n",
    "                loss=F.cross_entropy(logits,targets);losses.append(loss.item())\n",
    "                val_accuracy=utils.calculate_accuracy(logits,targets);accuracies.append(val_accuracy)\n",
    "\n",
    "            if logging:\n",
    "                wandb.log({'epoch':epoch,\n",
    "                            'Loss/val':np.mean(losses),\n",
    "                            'Accuracy/val':np.mean(val_accuracy)})\n",
    "\n",
    "\n",
    "        #save\n",
    "        if (epoch%save_freq==0) and (epoch!=0):\n",
    "            if not os.path.isdir(savedir):\n",
    "                os.mkdir(savedir)\n",
    "\n",
    "            save_dict={}\n",
    "            save_dict['kwargs']=kwargs\n",
    "            save_dict['model state dict']=SCL_model.state_dict()\n",
    "            save_dict['Optimiser state dict']=optimiser.state_dict()\n",
    "            save_dict['Epoch']=epoch\n",
    "\n",
    "            if logging:\n",
    "                save_dict['Run ID']=run.id\n",
    "            else:\n",
    "                save_dict['Run ID']=None\n",
    "\n",
    "            fname=os.path.join(savedir,f'epoch={epoch}_accuracy={val_accuracy}.ckpt')\n",
    "            with open(fname,'wb') as f:\n",
    "                pickle.dump(save_dict,f)\n",
    "                print('Checkpoint saved')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def expand_dim(t, dim, k):\n",
    "    t = t.unsqueeze(dim)\n",
    "    expand_shape = [-1] * len(t.shape)\n",
    "    expand_shape[dim] = k\n",
    "    return t.expand(*expand_shape)\n",
    "\n",
    "matrix=matrix.unsqueeze(2)\n",
    "questions=matrix[:,0:8,:,:]\n",
    "answers=matrix[:,8:,:,:,]\n",
    "\n",
    "answers = answers.unsqueeze(2)\n",
    "questions = expand_dim(questions, dim=1, k=8)\n",
    "\n",
    "permutations = torch.cat((questions, answers), dim=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DLenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09911b70b107ce1f1a26d3d965c92acabc3f780c628bdef8c12485070fed524b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
