{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import importlib\n",
    "import data\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load img\n",
    "#to load whole dataset will need to write a torch Dataset class\n",
    "\n",
    "import data; importlib.reload(data)\n",
    "batch_size=8\n",
    "\n",
    "datamodule=data.IRAVENDataModule(batch_size=batch_size)\n",
    "datamodule.setup()\n",
    "train_dataloader,val_dataloader,test_dataloader=datamodule.train_dataloader(),datamodule.val_dataloader(),datamodule.test_dataloader()\n",
    "\n",
    "print(train_dataloader.dataset.__len__(),test_dataloader.dataset.__len__(),val_dataloader.dataset.__len__())\n",
    "\n",
    "datamodule=data.IRAVENDataModule(batch_size=batch_size,split=(90,10,0))\n",
    "datamodule.setup()\n",
    "train_dataloader,val_dataloader,test_dataloader=datamodule.train_dataloader(),datamodule.val_dataloader(),datamodule.test_dataloader()\n",
    "\n",
    "print(train_dataloader.dataset.__len__(),test_dataloader.dataset.__len__(),val_dataloader.dataset.__len__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "train_dataset_fnames=train_dataloader.dataset.filenames\n",
    "test_dataset_fnames=test_dataloader.dataset.filenames\n",
    "\n",
    "\n",
    "def get_type_strs(structure):\n",
    "    types=structure[3]\n",
    "    types_str=eval(str(types)[1:])\n",
    "    return types_str\n",
    "\n",
    "types_str_dataset=[]\n",
    "for file in test_dataset_fnames:\n",
    "    structure=np.load(file)['structure']\n",
    "    types_str_dataset.append(get_type_strs(structure))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    frequency=collections.Counter(types_str_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=torch.full((5,5),4.0,requires_grad=True)\n",
    "t2=torch.full((5,5),2.0,requires_grad=False)\n",
    "t3=t1*t2\n",
    "print(t3.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing SCL model-mask divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing masked scl\n",
    "\n",
    "import masking,data,utils,models.SCL_model\n",
    "from data import IRAVENDataModule\n",
    "importlib.reload(masking)\n",
    "importlib.reload(data)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(models.SCL_model)\n",
    "\n",
    "from models.SCL_model import SCLTrainingWrapper,SCL\n",
    "\n",
    "#setup\n",
    "train=False\n",
    "test=True\n",
    "logging=True\n",
    "model_ckpt='/Users/iyngkarrankumar/Documents/AI/AVR-functional-modularity/SCL_pretrain_80.ckpt'\n",
    "task_path='datasets/light'\n",
    "save_freq= 10000\n",
    "batch_size=8\n",
    "split=(85,15,0)\n",
    "device=torch.device('cpu')\n",
    "\n",
    "#dataset setup\n",
    "if 1:\n",
    "    #task dataset\n",
    "    path=task_path\n",
    "    data_module=IRAVENDataModule(batch_size=batch_size,split=split)\n",
    "    data_module.prepare_data()\n",
    "    data_module.setup(root_dir=path)\n",
    "    train_dataloader_task,test_dataloader_task=data_module.train_dataloader(),data_module.test_dataloader()\n",
    "    x,y,*rest=next(iter(train_dataloader_task))\n",
    "\n",
    "    #NOT task dataset\n",
    "    path_='datasets/originals_masking'\n",
    "    data_module_=IRAVENDataModule(batch_size=batch_size,split=split)\n",
    "    data_module_.prepare_data()\n",
    "    data_module_.setup(root_dir=path_)\n",
    "    test_dataloader_not_task=data_module_.test_dataloader()\n",
    "\n",
    "#setup model\n",
    "if 1:\n",
    "    scl_kwargs={\n",
    "        \"image_size\":160,                            # size of image\n",
    "        \"set_size\": 9,                               # number of questions + 1 answer\n",
    "        \"conv_channels\": [1, 16, 16, 32, 32, 32],    # convolutional channel progression, 1 for greyscale, 3 for rgb\n",
    "        \"conv_output_dim\": 80,                       # model dimension, the output dimension of the vision net\n",
    "        \"attr_heads\": 10,                            # number of attribute heads\n",
    "        \"attr_net_hidden_dims\": [128],               # attribute scatter transform MLP hidden dimension(s)\n",
    "        \"rel_heads\": 80,                             # number of relationship heads\n",
    "        \"rel_net_hidden_dims\": [64, 32, 5] \n",
    "    }\n",
    "    model=SCL(**scl_kwargs)\n",
    "\n",
    "    #load\n",
    "    state_dict=utils.get_SCL_state_dict(model_ckpt)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    print(f'Model training: {model.training}')\n",
    "\n",
    "#initialise masked model\n",
    "if 1: \n",
    "    init_kwargs={\n",
    "        'model':model,\n",
    "        'train_dataloader':train_dataloader_task,\n",
    "        'test_dataloader1':test_dataloader_task,\n",
    "        'test_dataloader2':test_dataloader_not_task,\n",
    "        'device':device,\n",
    "        'savedir':'model_ckpts/FFN',\n",
    "    }\n",
    "\n",
    "    masked_scl=masking.MaskedSCLModel(init_kwargs)\n",
    "\n",
    "#train\n",
    "if 1:\n",
    "    train_kwargs={\n",
    "        'alpha':1e-6,\n",
    "        'n_epochs':2 if test else 10,\n",
    "        'n_batches':20 if test else 'full',\n",
    "        'val_every_n_steps':5 if test else 10,\n",
    "        'eval_every_n_steps':1e10,\n",
    "        'n_val_batches':2 if test else 100,\n",
    "        'n_eval_batches':2 if test else 100,\n",
    "        'save_freq':save_freq,\n",
    "        'logging':logging,\n",
    "\n",
    "        }\n",
    "\n",
    "    if train:\n",
    "        masked_scl.train(**train_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing masked scl\n",
    "\n",
    "import masking,data,utils,models.SCL_model\n",
    "from data import IRAVENDataModule\n",
    "importlib.reload(masking)\n",
    "importlib.reload(data)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(models.SCL_model)\n",
    "\n",
    "from models.SCL_model import SCLTrainingWrapper,SCL\n",
    "\n",
    "#setup\n",
    "train=False\n",
    "test=True\n",
    "logging=True\n",
    "model_ckpt='/Users/iyngkarrankumar/Documents/AI/AVR-functional-modularity/SCL_pretrain_80.ckpt'\n",
    "task_path='datasets/light'\n",
    "save_freq= 10000\n",
    "batch_size=8\n",
    "split=(85,15,0)\n",
    "device=torch.device('cpu')\n",
    "\n",
    "#dataset setup\n",
    "if 1:\n",
    "    #task dataset\n",
    "    path=task_path\n",
    "    data_module=IRAVENDataModule(batch_size=batch_size,split=split)\n",
    "    data_module.prepare_data()\n",
    "    data_module.setup(root_dir=path)\n",
    "    train_dataloader_task,test_dataloader_task=data_module.train_dataloader(),data_module.test_dataloader()\n",
    "    x,y,*rest=next(iter(train_dataloader_task))\n",
    "\n",
    "    #NOT task dataset\n",
    "    path_='datasets/originals_masking'\n",
    "    data_module_=IRAVENDataModule(batch_size=batch_size,split=split)\n",
    "    data_module_.prepare_data()\n",
    "    data_module_.setup(root_dir=path_)\n",
    "    test_dataloader_not_task=data_module_.test_dataloader()\n",
    "\n",
    "#setup model\n",
    "if 1:\n",
    "    scl_kwargs={\n",
    "        \"image_size\":160,                            # size of image\n",
    "        \"set_size\": 9,                               # number of questions + 1 answer\n",
    "        \"conv_channels\": [1, 16, 16, 32, 32, 32],    # convolutional channel progression, 1 for greyscale, 3 for rgb\n",
    "        \"conv_output_dim\": 80,                       # model dimension, the output dimension of the vision net\n",
    "        \"attr_heads\": 10,                            # number of attribute heads\n",
    "        \"attr_net_hidden_dims\": [128],               # attribute scatter transform MLP hidden dimension(s)\n",
    "        \"rel_heads\": 80,                             # number of relationship heads\n",
    "        \"rel_net_hidden_dims\": [64, 32, 5] \n",
    "    }\n",
    "    model=SCL(**scl_kwargs)\n",
    "\n",
    "    #load\n",
    "    state_dict=utils.get_SCL_state_dict(model_ckpt)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    print(f'Model training: {model.training}')\n",
    "\n",
    "#initialise masked model\n",
    "if 1: \n",
    "    init_kwargs={\n",
    "        'model':model,\n",
    "        'train_dataloader':train_dataloader_task,\n",
    "        'test_dataloader1':test_dataloader_task,\n",
    "        'test_dataloader2':test_dataloader_not_task,\n",
    "        'device':device,\n",
    "        'savedir':'model_ckpts/FFN',\n",
    "    }\n",
    "\n",
    "    masked_scl=masking.MaskedSCLModel(init_kwargs)\n",
    "\n",
    "#train\n",
    "if 1:\n",
    "    train_kwargs={\n",
    "        'alpha':1e-6,\n",
    "        'n_epochs':2 if test else 10,\n",
    "        'n_batches':20 if test else 'full',\n",
    "        'val_every_n_steps':5 if test else 10,\n",
    "        'eval_every_n_steps':1e10,\n",
    "        'n_val_batches':2 if test else 100,\n",
    "        'n_eval_batches':2 if test else 100,\n",
    "        'save_freq':save_freq,\n",
    "        'logging':logging,\n",
    "\n",
    "        }\n",
    "\n",
    "    if train:\n",
    "        masked_scl.train(**train_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "task_path='datasets/originals'\n",
    "\n",
    "\n",
    "\n",
    "data_module=IRAVENDataModule(batch_size=batch_size)\n",
    "data_module.prepare_data()\n",
    "data_module.setup(root_dir=task_path)\n",
    "train_dataloader_task,test_dataloader_task=data_module.train_dataloader(),data_module.test_dataloader()\n",
    "x,y,*rest=next(iter(train_dataloader_task))\n",
    "x,y=x.to(device),y.to(device)\n",
    "\n",
    "#compare accuracies\n",
    "if 1:\n",
    "    accuracies=[]\n",
    "    accuracies_masked=[]\n",
    "    n_batches=10\n",
    "\n",
    "\n",
    "    for batch_idx,batch in enumerate(test_dataloader_task):\n",
    "        print(batch_idx)\n",
    "        if batch_idx==n_batches:\n",
    "            break\n",
    "        x,y,*rest=batch\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        \n",
    "        x_=utils.prepare_input_SCL(x)\n",
    "        model.eval()\n",
    "        y_hat=model(x_)\n",
    "        acc=utils.calculate_accuracy(y_hat,y)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        y_hat_masked=masked_scl.forward(x)\n",
    "        acc_masked=utils.calculate_accuracy(y_hat_masked,y)\n",
    "        accuracies_masked.append(acc_masked)\n",
    "        \n",
    "        \n",
    "    print(np.mean(accuracies),np.mean(accuracies_masked))\n",
    "\n",
    "#calculate model feature differences\n",
    "if 0:\n",
    "\n",
    "    x_=utils.prepare_input_SCL(x)\n",
    "    model.eval() #model uses batchnorm, so put in eval\n",
    "    y_hat=model(x_)\n",
    "\n",
    "    y_hat_masked=masked_scl.forward(x)\n",
    "\n",
    "    model_features=model.layer_outputs\n",
    "    masked_features=masked_scl.layer_outputs\n",
    "    mse_difference=[]\n",
    "    names=['input','post-vision','post-attr','post-rels','post-logits']\n",
    "\n",
    "\n",
    "    for idx,name in enumerate(names):\n",
    "        mse_difference.append((name,F.mse_loss(model_features[idx],masked_features[idx]).item()))\n",
    "    print(mse_difference)\n",
    "\n",
    "if 0:\n",
    "    x_=utils.prepare_input_SCL(x)\n",
    "    x_in=copy.deepcopy(x_)\n",
    "    named_children=masking.get_named_children(model)\n",
    "    named_vision_modules={k:v for k,v in named_children.items() if 'vision' in k}\n",
    "    names=list(named_vision_modules.keys());names=['in']+names\n",
    "    vision_outputs=[]\n",
    "\n",
    "    for idx,(name,module) in enumerate(named_vision_modules.items()):\n",
    "        if idx==0:\n",
    "            b, m, n, c, h, w = x_in.shape\n",
    "            x_in = x_in.view(-1, c, h, w)\n",
    "            vision_outputs.append(x_in)\n",
    "            out=module(x_in)\n",
    "            vision_outputs.append(out)\n",
    "        else:\n",
    "            out=module(out)\n",
    "            vision_outputs.append(out)\n",
    "\n",
    "\n",
    "    out = masked_scl.forward(x)\n",
    "\n",
    "    mse_differences=[]\n",
    "    for (name,(t1,t2)) in zip(names,zip(vision_outputs,masked_scl.vision_outputs)):\n",
    "        diff=F.mse_loss(t1,t2).item()\n",
    "        mse_differences.append((name,diff))\n",
    "    print(mse_differences)\n",
    "    print(f'Mask sparsity: {utils.sparsity((masked_model.transform_logit_tensors()).values())}')\n",
    "\n",
    "\n",
    "if 0:\n",
    "\n",
    "    _=masked_scl.forward(x) #initialise binaries \n",
    "    params=masked_scl.param_dict\n",
    "    binaries=masked_scl.binaries\n",
    "    print(f'Sparsity: {utils.sparsity(binaries.values())}')\n",
    "\n",
    "    param_differences=[]\n",
    "\n",
    "    for name in named_vision_modules.keys():\n",
    "        try: \n",
    "            weight,bias=named_vision_modules[name].weight,named_vision_modules[name].bias\n",
    "            weight_,bias_=params[name+'.weight']*binaries[name+'.weight'],params[name+'.bias']*binaries[name+'.bias']\n",
    "            param_differences.append((name,F.mse_loss(weight,weight_).item(),F.mse_loss(bias,bias_).item()))\n",
    "        except:\n",
    "            #dealing with Flatten layer\n",
    "            pass \n",
    "\n",
    "\n",
    "    print(param_differences)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('RLenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b83ef0596b4451796c2d36149eda7cc6429c192cb05630e8e9d69e07d4dfbe4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
